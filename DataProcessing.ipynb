{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ed742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"allenai/WildChat-4.8M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e41eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset  \n",
    "print(ds[\"train\"].features) \n",
    "print(ds[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb787b1",
   "metadata": {},
   "source": [
    "## 1. only \"english\" and filter out those data without content including \"literature review\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99943f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train = ds[\"train\"]\n",
    "\n",
    "def is_english(example):\n",
    "    lang = example.get(\"language\") or \"\"\n",
    "    return isinstance(lang, str) and lang.lower() == \"english\"\n",
    "\n",
    "def contains_lit_review(example):\n",
    "    conv = example.get(\"conversation\") or example.get(\"conversations\") or []\n",
    "    if isinstance(conv, dict):\n",
    "        content = conv.get(\"content\") or conv.get(\"text\") or \"\"\n",
    "        return isinstance(content, str) and \"literature review\" in content.lower()\n",
    "    for msg in conv:\n",
    "        if isinstance(msg, str):\n",
    "            if \"literature review\" in msg.lower():\n",
    "                return True\n",
    "        if isinstance(msg, dict):\n",
    "            content = msg.get(\"content\")\n",
    "            if isinstance(content, str) and \"literature review\" in content.lower():\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "english_ds = train.filter(is_english)\n",
    "\n",
    "result_ds = english_ds.filter(contains_lit_review)\n",
    "\n",
    "print(\"matches:\", result_ds.num_rows)\n",
    "print(result_ds[:5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21312b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "import os\n",
    "\n",
    "output_dir = r\"C:\\Users\\25811\\Desktop\\Summer Search\\Yu\\Data_ds_format\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "result_ds.save_to_disk(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b1cb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds)                       \n",
    "print(ds[\"train\"].features)     \n",
    "print(ds[\"train\"].column_names) \n",
    "\n",
    "sample = ds[\"train\"][0]\n",
    "print(type(sample.get(\"conversation\")), sample.get(\"conversation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc43a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "try:\n",
    "    from dateutil import parser as _dateutil_parser\n",
    "except Exception:\n",
    "    _dateutil_parser = None\n",
    "\n",
    "ts_col = \"timestamp\"   \n",
    "batch_size = 10000\n",
    "\n",
    "def as_datetime(v):\n",
    "    if v is None:\n",
    "        return None\n",
    "    if isinstance(v, datetime):\n",
    "        return v\n",
    "    if isinstance(v, (int, float)):\n",
    "        return datetime.fromtimestamp(v/1000.0) if abs(v) > 1e11 else datetime.fromtimestamp(v)\n",
    "    if isinstance(v, str):\n",
    "        try:\n",
    "            return datetime.fromisoformat(v)\n",
    "        except Exception:\n",
    "            if _dateutil_parser:\n",
    "                try:\n",
    "                    return _dateutil_parser.parse(v)\n",
    "                except Exception:\n",
    "                    return None\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "\n",
    "counter = Counter()\n",
    "n = len(result_ds)\n",
    "for start in range(0, n, batch_size):\n",
    "    end = min(n, start + batch_size)\n",
    "    batch = result_ds[start:end]\n",
    "    vals = batch[ts_col]\n",
    "    for v in vals:\n",
    "        if isinstance(v, (list, tuple)):\n",
    "            for sub in v:\n",
    "                dt = as_datetime(sub)\n",
    "                if dt:\n",
    "                    counter[dt.date()] += 1\n",
    "        else:\n",
    "            dt = as_datetime(v)\n",
    "            if dt:\n",
    "                counter[dt.date()] += 1\n",
    "\n",
    "\n",
    "dates_sorted = sorted(counter.keys())\n",
    "counts = [counter[d] for d in dates_sorted]\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(dates_sorted, counts, marker='o', linestyle='-')\n",
    "plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Daily distribution of timestamps')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a907119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Simple moving average\n",
    "def moving_average(y, window):\n",
    "    kernel = np.ones(window) / window\n",
    "    return np.convolve(y, kernel, mode=\"same\")\n",
    "\n",
    "window = 7   # 7 / 14 / 30\n",
    "smoothed = moving_average(counts, window)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(dates_sorted, counts, alpha=0.4, label=\"raw\")\n",
    "plt.plot(dates_sorted, smoothed, color=\"red\", linewidth=2, label=f\"MA {window}\")\n",
    "plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.xticks(rotation=45); plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Daily distribution of timestamps')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = result_ds[0]\n",
    "print(type(sample.get(\"model\")), sample.get(\"model\"))\n",
    "print(result_ds.unique(\"model\"))\n",
    "print(type(sample.get(\"turn\")), sample.get(\"turn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48efb90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def model_family(name):\n",
    "    if not name: \n",
    "        return \"other\"\n",
    "    n = name.lower()\n",
    "    if n.startswith(\"gpt-4o\"):\n",
    "        return \"gpt-4o\"\n",
    "    if n.startswith(\"gpt-3.5\"):\n",
    "        return \"gpt-3.5-turbo\"\n",
    "    if n.startswith(\"gpt-4.1\"):\n",
    "        return \"gpt-4.1-mini\"\n",
    "    if n.startswith(\"gpt-4\"):\n",
    "        return \"gpt-4\"\n",
    "    if n.startswith(\"o1\"):\n",
    "        return \"o1\"\n",
    "    return \"other\"\n",
    "\n",
    "cnt = Counter()\n",
    "batch_size = 10000\n",
    "n = len(result_ds)\n",
    "for start in range(0, n, batch_size):\n",
    "    vals = result_ds[start:start+batch_size][\"model\"]   \n",
    "    cnt.update(model_family(v) for v in vals)\n",
    "\n",
    "print(\"counts:\", dict(cnt))\n",
    "\n",
    "labels, values = zip(*cnt.most_common())\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(labels, values, color=\"C0\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Model family counts\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c210b0",
   "metadata": {},
   "source": [
    "## Model * Turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31992fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def model_family5(name):\n",
    "    if not name:\n",
    "        return None\n",
    "    n = name.lower()\n",
    "    if n.startswith(\"gpt-4o\"):\n",
    "        return \"gpt-4o\"\n",
    "    if n.startswith(\"gpt-3.5\"):\n",
    "        return \"gpt-3.5-turbo\"\n",
    "    if n.startswith(\"gpt-4.1\"):\n",
    "        return \"gpt-4.1-mini\"\n",
    "    if n.startswith(\"gpt-4\"):\n",
    "        return \"gpt-4\"\n",
    "    if n.startswith(\"o1\"):\n",
    "        return \"o1\"\n",
    "    return None\n",
    "\n",
    "models = result_ds[\"model\"]\n",
    "turns  = result_ds[\"turn\"]\n",
    "\n",
    "samples = defaultdict(list)\n",
    "for m, t in zip(models, turns):\n",
    "    fam = model_family5(m)\n",
    "    if fam is None:\n",
    "        continue\n",
    "    try:\n",
    "        val = int(t)\n",
    "    except Exception:\n",
    "        continue\n",
    "    samples[fam].append(val)\n",
    "\n",
    "order = [\"gpt-4o\", \"gpt-3.5-turbo\", \"gpt-4.1-mini\", \"gpt-4\", \"o1\"]\n",
    "data = []\n",
    "labels = []\n",
    "for fam in order:\n",
    "    lst = samples.get(fam, [])\n",
    "    if not lst:\n",
    "        continue\n",
    "    data.append(lst)\n",
    "    labels.append(f\"{fam}\\n(n={len(lst)})\")\n",
    "\n",
    "if not data:\n",
    "    raise RuntimeError(\"Fail to collect turn data\")\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.boxplot(data, tick_labels=labels, showfliers=False)\n",
    "plt.ylabel(\"turn (int)\")\n",
    "plt.title(\"Distribution of 'turn' by model family\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0844b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def model_family5(name):\n",
    "    if not name:\n",
    "        return None\n",
    "    n = name.lower()\n",
    "    if n.startswith(\"gpt-4o\"):\n",
    "        return \"gpt-4o\"\n",
    "    if n.startswith(\"gpt-3.5\"):\n",
    "        return \"gpt-3.5-turbo\"\n",
    "    if n.startswith(\"gpt-4.1\"):\n",
    "        return \"gpt-4.1-mini\"\n",
    "    if n.startswith(\"gpt-4\"):\n",
    "        return \"gpt-4\"\n",
    "    if n.startswith(\"o1\"):\n",
    "        return \"o1\"\n",
    "    return None\n",
    "\n",
    "models = result_ds[\"model\"]\n",
    "turns  = result_ds[\"turn\"]\n",
    "samples = defaultdict(list)\n",
    "for m, t in zip(models, turns):\n",
    "    fam = model_family5(m)\n",
    "    if fam is None:\n",
    "        continue\n",
    "    try:\n",
    "        val = int(t)\n",
    "    except Exception:\n",
    "        continue\n",
    "    samples[fam].append(val)\n",
    "\n",
    "order = [\"gpt-4o\", \"gpt-3.5-turbo\", \"gpt-4.1-mini\", \"gpt-4\", \"o1\"]\n",
    "\n",
    "# compute and print robust stats\n",
    "print(\"family\\tcount\\tmedian\\tIQR\\t10th\\t90th\\tmean\")\n",
    "for fam in order:\n",
    "    lst = np.array(samples.get(fam, []))\n",
    "    if lst.size == 0:\n",
    "        continue\n",
    "    med = np.median(lst)\n",
    "    q1, q3 = np.percentile(lst, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    p10, p90 = np.percentile(lst, [10, 90])\n",
    "    mean = np.mean(lst)\n",
    "    print(f\"{fam}\\t{len(lst)}\\t{med:.2f}\\t{iqr:.2f}\\t{p10:.2f}\\t{p90:.2f}\\t{mean:.2f}\")\n",
    "\n",
    "# 1) boxplot on log1p scale (recommended for skewed counts)\n",
    "data_log = [np.log1p(samples[f]) for f in order if samples.get(f)]\n",
    "labels = [f\"{f}\\n(n={len(samples[f])})\" for f in order if samples.get(f)]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "try:\n",
    "    plt.boxplot(data_log, tick_labels=labels, showfliers=False)\n",
    "except TypeError:\n",
    "    plt.boxplot(data_log, labels=labels, showfliers=False)\n",
    "plt.ylabel(\"log1p(turn)\")\n",
    "plt.title(\"Boxplot (log1p scale) of 'turn' by model family\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2) violin + jittered scatter on original scale (shows raw spread)\n",
    "data = [samples[f] for f in order if samples.get(f)]\n",
    "pos = np.arange(1, len(data) + 1)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "# violin (matplotlib)\n",
    "parts = plt.violinplot(data, positions=pos, showmeans=False, showextrema=True)\n",
    "for pc in parts['bodies']:\n",
    "    pc.set_alpha(0.6)\n",
    "# jittered scatter\n",
    "for i, lst in enumerate(data, start=1):\n",
    "    y = np.array(lst)\n",
    "    x = np.random.normal(i, 0.08, size=y.size)  # small jitter\n",
    "    plt.scatter(x, y, s=5, alpha=0.3, color='k')\n",
    "\n",
    "plt.xticks(pos, labels, rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"turn (int)\")\n",
    "plt.title(\"Violin + jittered points (original scale)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6321be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A: ignore turn > cutoff\n",
    "cutoff = 40\n",
    "filtered = {f: [v for v in samples.get(f, []) if v <= cutoff] for f in order}\n",
    "removed_counts = {f: len(samples.get(f, [])) - len(filtered[f]) for f in order}\n",
    "print(\"removed (per family) when cutoff=%d:\" % cutoff, removed_counts)\n",
    "\n",
    "data = [filtered[f] for f in order if filtered.get(f)]\n",
    "labels = [f\"{f}\\n(n={len(samples.get(f,[]))})\" for f in order if filtered.get(f)]\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "parts = plt.violinplot(data, positions=np.arange(1, len(data)+1), showmeans=False, showextrema=True)\n",
    "for pc in parts['bodies']:\n",
    "    pc.set_alpha(0.6)\n",
    "# jitter points\n",
    "for i, lst in enumerate(data, start=1):\n",
    "    y = np.array(lst)\n",
    "    if y.size == 0:\n",
    "        continue\n",
    "    x = np.random.normal(i, 0.06, size=y.size)\n",
    "    plt.scatter(x, y, s=8, alpha=0.6, color='k')\n",
    "plt.xticks(np.arange(1, len(data)+1), labels, rotation=45, ha='right')\n",
    "plt.ylabel(\"turn (int)\")\n",
    "plt.title(f\"Violin + jitter (turn <= {cutoff})\")\n",
    "plt.ylim(-0.5, cutoff + 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# B: log scale\n",
    "data_all = [samples[f] for f in order if samples.get(f)]\n",
    "labels_all = [f\"{f}\\n(n={len(samples.get(f,[]))})\" for f in order if samples.get(f)]\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "parts = plt.violinplot(data_all, positions=np.arange(1, len(data_all)+1), showmeans=False, showextrema=True)\n",
    "for pc in parts['bodies']:\n",
    "    pc.set_alpha(0.6)\n",
    "for i, lst in enumerate(data_all, start=1):\n",
    "    y = np.array(lst)\n",
    "    if y.size == 0:\n",
    "        continue\n",
    "    x = np.random.normal(i, 0.06, size=y.size)\n",
    "    plt.scatter(x, y, s=6, alpha=0.5, color='k')\n",
    "plt.xticks(np.arange(1, len(data_all)+1), labels_all, rotation=45, ha='right')\n",
    "plt.yscale('log')\n",
    "plt.ylabel(\"turn (int), log scale\")\n",
    "plt.title(\"Violin + jitter (all points, log y-axis)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01861278",
   "metadata": {},
   "source": [
    "## Analysis With Characterist numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea6921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_contents(conv):\n",
    "    if conv is None:\n",
    "        return []\n",
    "    if isinstance(conv, (list, tuple)):\n",
    "        texts = []\n",
    "        for msg in conv:\n",
    "            if isinstance(msg, str):\n",
    "                texts.append(msg)\n",
    "            elif isinstance(msg, dict):\n",
    "                c = msg.get(\"content\") or msg.get(\"text\")\n",
    "                if isinstance(c, str):\n",
    "                    texts.append(c)\n",
    "        return texts\n",
    "    return []\n",
    "\n",
    "def count_words_from_text(s):\n",
    "    if not s:\n",
    "        return 0\n",
    "    return len(s.split())\n",
    "\n",
    "models = result_ds[\"model\"]\n",
    "turns  = result_ds[\"turn\"]\n",
    "convs  = result_ds[\"conversation\"]\n",
    "\n",
    "avg_words_per_turn = []\n",
    "skipped = 0\n",
    "for m, t, conv in zip(models, turns, convs):\n",
    "    try:\n",
    "        turn_val = int(t)\n",
    "    except Exception:\n",
    "        skipped += 1\n",
    "        continue\n",
    "    if turn_val <= 0:\n",
    "        skipped += 1\n",
    "        continue\n",
    "    texts = extract_contents(conv)\n",
    "    total_words = sum(count_words_from_text(x) for x in texts)\n",
    "    avg = total_words / turn_val\n",
    "    avg_words_per_turn.append(avg)\n",
    "\n",
    "avg_arr = np.array(avg_words_per_turn)\n",
    "print(f\"kept samples: {avg_arr.size}, skipped (bad turn/zero): {skipped}\")\n",
    "\n",
    "if avg_arr.size:\n",
    "    med = np.median(avg_arr)\n",
    "    q1, q3 = np.percentile(avg_arr, [25,75])\n",
    "    iqr = q3 - q1\n",
    "    p10, p90 = np.percentile(avg_arr, [10,90])\n",
    "    mean = np.mean(avg_arr)\n",
    "    print(\"metric\\tcount\\tmedian\\tIQR\\t10th\\t90th\\tmean\")\n",
    "    print(f\"avg_words_per_turn\\t{avg_arr.size}\\t{med:.2f}\\t{iqr:.2f}\\t{p10:.2f}\\t{p90:.2f}\\t{mean:.2f}\")\n",
    "else:\n",
    "    raise RuntimeError(\"no valid avg_words_per_turn data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d7a7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 1: histplot\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(avg_arr, bins=40, color=\"C0\", alpha=0.8)\n",
    "plt.xlabel(\"avg words per turn\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"Histogram of avg words per turn\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plot 2: boxplot（log1p）\n",
    "# plt.figure(figsize=(6,4))\n",
    "# try:\n",
    "#     plt.boxplot([np.log1p(avg_arr)], tick_labels=[\"log1p(avg words/turn)\"], showfliers=False)\n",
    "# except TypeError:\n",
    "#     plt.boxplot([np.log1p(avg_arr)], labels=[\"log1p(avg words/turn)\"], showfliers=False)\n",
    "# plt.title(\"Boxplot (log1p) of avg words per turn\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# plot 3: violin + jitter \n",
    "# cutoff = 5000.0  \n",
    "# vis_vals = avg_arr[avg_arr <= cutoff]\n",
    "# print(f\"visualizing {vis_vals.size} points (<= {cutoff}), removed {avg_arr.size - vis_vals.size}\")\n",
    "# plt.figure(figsize=(8,4))\n",
    "# parts = plt.violinplot([vis_vals], showmeans=False, showextrema=True)\n",
    "# for pc in parts.get('bodies', []):\n",
    "#     pc.set_alpha(0.6)\n",
    "# # jitter points\n",
    "# x = np.random.normal(1, 0.04, size=vis_vals.size)\n",
    "# plt.scatter(x, vis_vals, s=8, alpha=0.6, color='k')\n",
    "# plt.xticks([1], [f\"avg words/turn\\n(n={vis_vals.size})\"])\n",
    "# plt.ylabel(\"avg words per turn\")\n",
    "# plt.title(f\"Violin + jitter (values <= {cutoff})\")\n",
    "# plt.ylim(-0.5, cutoff + 1)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc1222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def model_family5(name):\n",
    "    if not name:\n",
    "        return None\n",
    "    n = name.lower()\n",
    "    if n.startswith(\"gpt-4o\"):\n",
    "        return \"gpt-4o\"\n",
    "    if n.startswith(\"gpt-3.5\"):\n",
    "        return \"gpt-3.5-turbo\"\n",
    "    if n.startswith(\"gpt-4.1\"):\n",
    "        return \"gpt-4.1-mini\"\n",
    "    if n.startswith(\"gpt-4\"):\n",
    "        return \"gpt-4\"\n",
    "    if n.startswith(\"o1\"):\n",
    "        return \"o1\"\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "models = result_ds[\"model\"]\n",
    "turns  = avg_arr\n",
    "samples = defaultdict(list)\n",
    "for m, t in zip(models, turns):\n",
    "    fam = model_family5(m)\n",
    "    if fam is None:\n",
    "        continue\n",
    "    try:\n",
    "        val = int(t)\n",
    "    except Exception:\n",
    "        continue\n",
    "    samples[fam].append(val)\n",
    "\n",
    "order = [\"gpt-4o\", \"gpt-3.5-turbo\", \"gpt-4.1-mini\", \"gpt-4\", \"o1\"]\n",
    "\n",
    "# compute and print robust stats\n",
    "print(\"family\\tcount\\tmedian\\tIQR\\t10th\\t90th\\tmean\")\n",
    "for fam in order:\n",
    "    lst = np.array(samples.get(fam, []))\n",
    "    if lst.size == 0:\n",
    "        continue\n",
    "    med = np.median(lst)\n",
    "    q1, q3 = np.percentile(lst, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    p10, p90 = np.percentile(lst, [10, 90])\n",
    "    mean = np.mean(lst)\n",
    "    print(f\"{fam}\\t{len(lst)}\\t{med:.2f}\\t{iqr:.2f}\\t{p10:.2f}\\t{p90:.2f}\\t{mean:.2f}\")\n",
    "\n",
    "# Basic Boxplot\n",
    "data = []\n",
    "labels = []\n",
    "for fam in order:\n",
    "    lst = samples.get(fam, [])\n",
    "    if not lst:\n",
    "        continue\n",
    "    data.append(lst)\n",
    "    labels.append(f\"{fam}\\n(n={len(lst)})\")\n",
    "\n",
    "if not data:\n",
    "    raise RuntimeError(\"Fail to collect turn data\")\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.boxplot(data, tick_labels=labels, showfliers=False)\n",
    "plt.ylabel(\"Avg words (int)\")\n",
    "plt.title(\"Distribution of 'Avg words' by model family\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 1) boxplot on log1p scale (recommended for skewed counts)\n",
    "data_log = [np.log1p(samples[f]) for f in order if samples.get(f)]\n",
    "labels = [f\"{f}\\n(n={len(samples[f])})\" for f in order if samples.get(f)]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.boxplot(data_log, tick_labels=labels, showfliers=False)\n",
    "plt.ylabel(\"log1p(Avg words)\")\n",
    "plt.title(\"Boxplot (log1p scale) of 'Avg words' by model family\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2) violin + jittered scatter on original scale (shows raw spread)\n",
    "data = [samples[f] for f in order if samples.get(f)]\n",
    "pos = np.arange(1, len(data) + 1)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "# violin (matplotlib)\n",
    "parts = plt.violinplot(data, positions=pos, showmeans=False, showextrema=True)\n",
    "for pc in parts['bodies']:\n",
    "    pc.set_alpha(0.6)\n",
    "# jittered scatter\n",
    "for i, lst in enumerate(data, start=1):\n",
    "    y = np.array(lst)\n",
    "    x = np.random.normal(i, 0.08, size=y.size)  # small jitter\n",
    "    plt.scatter(x, y, s=5, alpha=0.3, color='k')\n",
    "\n",
    "plt.xticks(pos, labels, rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Avg words (int)\")\n",
    "plt.title(\"Violin + jittered points (original scale)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd52480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A: turn > cutoff\n",
    "cutoff = 40\n",
    "filtered = {f: [v for v in samples.get(f, []) if v <= cutoff] for f in order}\n",
    "removed_counts = {f: len(samples.get(f, [])) - len(filtered[f]) for f in order}\n",
    "print(\"removed (per family) when cutoff=%d:\" % cutoff, removed_counts)\n",
    "\n",
    "data = [filtered[f] for f in order if filtered.get(f)]\n",
    "labels = [f\"{f}\\n(n={len(samples.get(f,[]))})\" for f in order if filtered.get(f)]\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "parts = plt.violinplot(data, positions=np.arange(1, len(data)+1), showmeans=False, showextrema=True)\n",
    "for pc in parts['bodies']:\n",
    "    pc.set_alpha(0.6)\n",
    "# jitter points\n",
    "for i, lst in enumerate(data, start=1):\n",
    "    y = np.array(lst)\n",
    "    if y.size == 0:\n",
    "        continue\n",
    "    x = np.random.normal(i, 0.06, size=y.size)\n",
    "    plt.scatter(x, y, s=8, alpha=0.6, color='k')\n",
    "plt.xticks(np.arange(1, len(data)+1), labels, rotation=45, ha='right')\n",
    "plt.ylabel(\"turn (int)\")\n",
    "plt.title(f\"Violin + jitter (turn <= {cutoff})\")\n",
    "plt.ylim(-0.5, cutoff + 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# B: \n",
    "data_all = [samples[f] for f in order if samples.get(f)]\n",
    "labels_all = [f\"{f}\\n(n={len(samples.get(f,[]))})\" for f in order if samples.get(f)]\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "parts = plt.violinplot(data_all, positions=np.arange(1, len(data_all)+1), showmeans=False, showextrema=True)\n",
    "for pc in parts['bodies']:\n",
    "    pc.set_alpha(0.6)\n",
    "for i, lst in enumerate(data_all, start=1):\n",
    "    y = np.array(lst)\n",
    "    if y.size == 0:\n",
    "        continue\n",
    "    x = np.random.normal(i, 0.06, size=y.size)\n",
    "    plt.scatter(x, y, s=6, alpha=0.5, color='k')\n",
    "plt.xticks(np.arange(1, len(data_all)+1), labels_all, rotation=45, ha='right')\n",
    "plt.yscale('log')\n",
    "plt.ylabel(\"turn (int), log scale\")\n",
    "plt.title(\"Violin + jitter (all points, log y-axis)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2a28ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ds[\"conversation\"][0]\n",
    "print(result_ds.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0237a1",
   "metadata": {},
   "source": [
    "## All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971162fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "try:\n",
    "    from dateutil import parser as _dateutil_parser\n",
    "except Exception:\n",
    "    _dateutil_parser = None\n",
    "\n",
    "ts_col = \"timestamp\"   \n",
    "batch_size = 10000     \n",
    "\n",
    "def as_datetime(v):\n",
    "    if v is None:\n",
    "        return None\n",
    "    if isinstance(v, datetime):\n",
    "        return v\n",
    "    if isinstance(v, (int, float)):\n",
    "        return datetime.fromtimestamp(v/1000.0) if abs(v) > 1e11 else datetime.fromtimestamp(v)\n",
    "    if isinstance(v, str):\n",
    "        try:\n",
    "            return datetime.fromisoformat(v)\n",
    "        except Exception:\n",
    "            if _dateutil_parser:\n",
    "                try:\n",
    "                    return _dateutil_parser.parse(v)\n",
    "                except Exception:\n",
    "                    return None\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "\n",
    "print(\"columns:\", train.column_names)\n",
    "assert ts_col in train.column_names, f\"can not find {ts_col}\"\n",
    "\n",
    "counter_all = Counter()\n",
    "n = len(train)\n",
    "for start in range(0, n, batch_size):\n",
    "    end = min(n, start + batch_size)\n",
    "    batch = train[start:end]\n",
    "    vals = batch[ts_col]\n",
    "    for v in vals:\n",
    "        if isinstance(v, (list, tuple)):\n",
    "            for sub in v:\n",
    "                dt = as_datetime(sub)\n",
    "                if dt:\n",
    "                    counter_all[dt.date()] += 1\n",
    "        else:\n",
    "            dt = as_datetime(v)\n",
    "            if dt:\n",
    "                counter_all[dt.date()] += 1\n",
    "\n",
    "if not counter_all:\n",
    "    raise RuntimeError(\"no valid time\")\n",
    "\n",
    "dates_sorted_all = sorted(counter_all.keys())\n",
    "counts_all = [counter_all[d] for d in dates_sorted_all]\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(dates_sorted_all, counts_all, marker='o', linestyle='-')\n",
    "plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Daily distribution of all timestamps')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0231ce",
   "metadata": {},
   "source": [
    "## Topic Analysis\n",
    "### Frequent Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd96733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_conv(conv):\n",
    "    if conv is None:\n",
    "        return []\n",
    "    if isinstance(conv, dict):\n",
    "        # single message dict or nested conversation dict\n",
    "        if \"content\" in conv or \"text\" in conv:\n",
    "            return [conv]\n",
    "        conv = conv.get(\"conversation\") or conv.get(\"conversations\")\n",
    "        if isinstance(conv, dict):\n",
    "            return [conv]\n",
    "    if isinstance(conv, (list, tuple)):\n",
    "        return list(conv)\n",
    "    return []\n",
    "\n",
    "def extract_user_texts(dataset, conv_col=\"conversation\", hash_col=\"conversation_hash\"):\n",
    "    \"\"\"\n",
    "    从 dataset 中提取：每条 record 的 conversation 中 role=='user' 的 content/text，\n",
    "    返回 list of dict: {conversation_hash, turn_index, text}\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for record in dataset:\n",
    "        conv = normalize_conv(record.get(conv_col))\n",
    "        conv_hash = record.get(hash_col) or record.get(\"conversation_hash\") or None\n",
    "        for i, turn in enumerate(conv):\n",
    "            if isinstance(turn, dict):\n",
    "                role = (turn.get(\"role\") or \"\").lower()\n",
    "                text = turn.get(\"content\") or turn.get(\"text\") or \"\"\n",
    "                if role == \"user\" and isinstance(text, str) and text.strip():\n",
    "                    out.append({\"conversation_hash\": conv_hash, \"turn_index\": i, \"text\": text.strip()})\n",
    "    return out\n",
    "\n",
    "user_texts = extract_user_texts(english_ds)   \n",
    "print(\"extracted:\", len(user_texts))\n",
    "import pandas as pd\n",
    "df_user = pd.DataFrame(user_texts)\n",
    "display(df_user.head())\n",
    "\n",
    "# out_csv = \"english_user_texts.csv\"\n",
    "# df_user[[\"text\", \"conversation_hash\", \"turn_index\"]].to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "# print(\"saved:\", out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26209b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_conv(conv):\n",
    "    if conv is None:\n",
    "        return []\n",
    "    if isinstance(conv, dict):\n",
    "        # single message dict or nested conversation dict\n",
    "        if \"content\" in conv or \"text\" in conv:\n",
    "            return [conv]\n",
    "        conv = conv.get(\"conversation\") or conv.get(\"conversations\")\n",
    "        if isinstance(conv, dict):\n",
    "            return [conv]\n",
    "    if isinstance(conv, (list, tuple)):\n",
    "        return list(conv)\n",
    "    return []\n",
    "# ...existing code...\n",
    "\n",
    "def stream_user_texts_to_csv(dataset, out_csv=\"english_user_texts_stream.csv\",\n",
    "                             conv_col=\"conversation\", hash_col=\"conversation_hash\",\n",
    "                             show_progress=True):\n",
    "    \"\"\"\n",
    "    使用 dataset.to_iterable_dataset() 流式读取并把 user role 的 content 直接写入 CSV。\n",
    "    低内存，适合大数据集。\n",
    "    \"\"\"\n",
    "    import csv\n",
    "    try:\n",
    "        it = dataset.to_iterable_dataset()\n",
    "    except Exception:\n",
    "        it = dataset\n",
    "\n",
    "    written = 0\n",
    "    with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"conversation_hash\", \"turn_index\", \"text\"])\n",
    "        for i, record in enumerate(it):\n",
    "            conv = normalize_conv(record.get(conv_col) or record.get(\"conversations\"))\n",
    "            conv_hash = record.get(hash_col) or record.get(\"conversation_hash\") or None\n",
    "            for idx, turn in enumerate(conv):\n",
    "                if isinstance(turn, dict):\n",
    "                    role = (turn.get(\"role\") or \"\").lower()\n",
    "                    text = turn.get(\"content\") or turn.get(\"text\") or \"\"\n",
    "                    if role == \"user\" and isinstance(text, str) and text.strip():\n",
    "                        writer.writerow([conv_hash, idx, text.strip()])\n",
    "                        written += 1\n",
    "            if show_progress and (i + 1) % 10000 == 0:\n",
    "                print(f\"Processed {i+1} records, written {written} user turns...\")\n",
    "    print(f\"Done. total user-turn rows written: {written}. saved to: {out_csv}\")\n",
    "    return out_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a2b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用示例（在 notebook cell 中运行）\n",
    "# 如果 english_ds 支持 iterable：\n",
    "out = stream_user_texts_to_csv(english_ds, out_csv=\"english_user_texts_stream.csv\")\n",
    "# 否则使用分块：\n",
    "# out = chunked_user_texts_to_csv(english_ds, out_csv=\"english_user_texts_chunks.csv\", chunk_size=2000)\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a332b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_user_texts_to_csv(dataset, out_csv=\"english_user_texts_stream.csv\",\n",
    "                             conv_col=\"conversation\", hash_col=\"conversation_hash\",\n",
    "                             show_progress=True, max_user_turns=None, max_records=None):\n",
    "    \"\"\"\n",
    "    流式写入 user role 的 content 到 CSV。\n",
    "    - max_user_turns: 如果不为 None，最多写入这么多 user-turn（达到后立即停止）。\n",
    "    - max_records: 如果不为 None，最多扫描这么多 dataset 记录（达到后停止）。\n",
    "    返回 (out_csv, written_user_turns, scanned_records)\n",
    "    \"\"\"\n",
    "    import csv\n",
    "    try:\n",
    "        it = dataset.to_iterable_dataset()\n",
    "    except Exception:\n",
    "        it = dataset\n",
    "\n",
    "    written = 0\n",
    "    scanned = 0\n",
    "    with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"conversation_hash\", \"turn_index\", \"text\"])\n",
    "        for i, record in enumerate(it):\n",
    "            scanned += 1\n",
    "            conv = normalize_conv(record.get(conv_col) or record.get(\"conversations\"))\n",
    "            conv_hash = record.get(hash_col) or record.get(\"conversation_hash\") or None\n",
    "            for idx, turn in enumerate(conv):\n",
    "                if isinstance(turn, dict):\n",
    "                    role = (turn.get(\"role\") or \"\").lower()\n",
    "                    text = turn.get(\"content\") or turn.get(\"text\") or \"\"\n",
    "                    if role == \"user\" and isinstance(text, str) and text.strip():\n",
    "                        writer.writerow([conv_hash, idx, text.strip()])\n",
    "                        written += 1\n",
    "                        if max_user_turns is not None and written >= int(max_user_turns):\n",
    "                            if show_progress:\n",
    "                                print(f\"Reached max_user_turns={max_user_turns} after scanning {scanned} records.\")\n",
    "                            print(f\"Done. written={written}, scanned={scanned}. saved to: {out_csv}\")\n",
    "                            return out_csv, written, scanned\n",
    "            if show_progress and (i + 1) % 10000 == 0:\n",
    "                print(f\"Processed {i+1} records, written {written} user turns...\")\n",
    "            if max_records is not None and scanned >= int(max_records):\n",
    "                if show_progress:\n",
    "                    print(f\"Reached max_records={max_records}.\")\n",
    "                break\n",
    "    print(f\"Done. total user-turn rows written: {written}, scanned records: {scanned}. saved to: {out_csv}\")\n",
    "    return out_csv, written, scanned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb3620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, written, scanned = stream_user_texts_to_csv(english_ds,\n",
    "                                                out_csv=\"D:\\\\english_user_texts_stream.csv\",\n",
    "                                                max_user_turns=100000,\n",
    "                                                max_records=50000)\n",
    "print(out, written, scanned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "729fdc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_hash</th>\n",
       "      <th>turn_index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cf1267ca6b2f6fccc9c36652a00059a1</td>\n",
       "      <td>0</td>\n",
       "      <td>Old age PT hx of DM, HTN, dyslipidemia His ECG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59c72510f3143025f94f75b883b026bd</td>\n",
       "      <td>0</td>\n",
       "      <td>i wanna you to write me terms &amp; conditions and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa7c3f49343e097be66442288abd1dac</td>\n",
       "      <td>0</td>\n",
       "      <td>Let A, B, and C be events with\\n\\nProb[A] = 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa7c3f49343e097be66442288abd1dac</td>\n",
       "      <td>2</td>\n",
       "      <td>Question 4 options:\\nLet A and B be events wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aa7c3f49343e097be66442288abd1dac</td>\n",
       "      <td>4</td>\n",
       "      <td>Alice and Bob share binary communication chann...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  conversation_hash  turn_index  \\\n",
       "0  cf1267ca6b2f6fccc9c36652a00059a1           0   \n",
       "1  59c72510f3143025f94f75b883b026bd           0   \n",
       "2  aa7c3f49343e097be66442288abd1dac           0   \n",
       "3  aa7c3f49343e097be66442288abd1dac           2   \n",
       "4  aa7c3f49343e097be66442288abd1dac           4   \n",
       "\n",
       "                                                text  \n",
       "0  Old age PT hx of DM, HTN, dyslipidemia His ECG...  \n",
       "1  i wanna you to write me terms & conditions and...  \n",
       "2  Let A, B, and C be events with\\n\\nProb[A] = 0....  \n",
       "3  Question 4 options:\\nLet A and B be events wit...  \n",
       "4  Alice and Bob share binary communication chann...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"D:\\english_user_texts_stream.csv\", encoding=\"utf-8-sig\")\n",
    "print(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f95f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word frequency (tokenize -> Counter)\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CSV_PATH = r\"D:\\english_user_texts_stream.csv\"\n",
    "USE_CHUNKS = False\n",
    "\n",
    "# Simple tokenizer\n",
    "TOKEN_RE = re.compile(r\"[A-Za-z0-9']+\")\n",
    "\n",
    "STOPWORDS = {\n",
    "    'the','and','to','of','a','in','is','it','for','that','on','i','you','be','are',\n",
    "    'with','this','as','was','but','not','or','have','will','my','we','me','so','if',\n",
    "    '0','1','2','3','4','5','6','7','8','9','he','she','they','at','by','an','from','all','your',\n",
    "    'there','what','about','just','like','no','do','when','get','can','would','how','out','up',\n",
    "    'one','more','some','them','his','her','been','who','now','did','than','then','also','because',\n",
    "    'into','could','any','other','only','new','these','see','after','over','such','many','much',\n",
    "    'where','why','those','us','am','too','may','should','well','very','here','most','way','make','even',\n",
    "    'a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',\n",
    "    ',','.','!','?',';','-','--','\"',\"'\",'(',')','[',']','{','}','...',\n",
    "    'has','had','shall','upon','whereas','therefore','herein','therein','their','its','doth','hath',\n",
    "    '10','11','12','13','14','15','16','17','18','19','20','its','im','dont','cant','ive','youre','thats',\n",
    "    'firsr','second','third','also','thus','hence','which','while','during','among','between','within',\n",
    "    'each','every','either','neither','lest','whilst','moreover','furthermore','additionally'\n",
    "}\n",
    "\n",
    "def tokenize(text):\n",
    "    if not isinstance(text, str): return []\n",
    "    toks = TOKEN_RE.findall(text.lower())\n",
    "    return [t for t in toks if t and t not in STOPWORDS]\n",
    "\n",
    "def freq_from_df(df_iterable):\n",
    "    cnt = Counter()\n",
    "    total = 0\n",
    "    for txt in df_iterable:\n",
    "        toks = tokenize(txt)\n",
    "        cnt.update(toks)\n",
    "        total += len(toks)\n",
    "    return cnt, total\n",
    "\n",
    "\n",
    "counter, total_tokens = freq_from_df(df['text'])\n",
    "\n",
    "\n",
    "TOP_N = 30\n",
    "top = counter.most_common(TOP_N)\n",
    "print(\"Total tokens:\", total_tokens)\n",
    "print(\"Top\", TOP_N, \"words:\", top[:10])\n",
    "\n",
    "\n",
    "words, counts = zip(*top) if top else ([],[])\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(range(len(counts)), counts, color='C0')\n",
    "plt.xticks(range(len(words)), words, rotation=45, ha='right')\n",
    "plt.title(f\"Top {TOP_N} words (tokens={total_tokens})\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e3bb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New cell: extract noun frequencies\n",
    "import math\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TOP_N = 40\n",
    "\n",
    "try:\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\",\"textcat\"])\n",
    "    def extract_nouns(text):\n",
    "        if not isinstance(text, str): return []\n",
    "        doc = nlp(text)\n",
    "        # 使用 lemma 归一化（小写），保留普通名词和专有名词\n",
    "        return [tok.lemma_.lower() for tok in doc if tok.pos_ in (\"NOUN\",\"PROPN\")]\n",
    "except Exception:\n",
    "    # 回退到 nltk 的简单规则性 POS 标注（不做词形还原）\n",
    "    import nltk\n",
    "    try:\n",
    "        nltk.data.find(\"tokenizers/punkt\")\n",
    "    except Exception:\n",
    "        nltk.download(\"punkt\")\n",
    "    try:\n",
    "        nltk.data.find(\"taggers/averaged_perceptron_tagger\")\n",
    "    except Exception:\n",
    "        nltk.download(\"averaged_perceptron_tagger\")\n",
    "    from nltk import word_tokenize, pos_tag\n",
    "    def extract_nouns(text):\n",
    "        if not isinstance(text, str): return []\n",
    "        toks = TOKEN_RE.findall(text.lower())\n",
    "        tagged = pos_tag(toks)\n",
    "        return [w for w,tag in tagged if tag.startswith(\"NN\")]\n",
    "\n",
    "# 统计\n",
    "noun_counter = Counter()\n",
    "total_noun_tokens = 0\n",
    "for txt in df['text']:\n",
    "    nouns = extract_nouns(txt)\n",
    "    noun_counter.update(nouns)\n",
    "    total_noun_tokens += len(nouns)\n",
    "\n",
    "top_nouns = noun_counter.most_common(TOP_N)\n",
    "print(\"Total noun tokens:\", total_noun_tokens)\n",
    "print(f\"Top {TOP_N} nouns:\", top_nouns[:20])\n",
    "\n",
    "# 可视化（Top N）\n",
    "words, counts = zip(*top_nouns) if top_nouns else ([],[])\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(range(len(counts)), counts, color='C2')\n",
    "plt.xticks(range(len(words)), words, rotation=45, ha='right')\n",
    "plt.title(f\"Top {TOP_N} nouns (noun tokens={total_noun_tokens})\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b990b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sentence-transformers embeddings for df['text']\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import os\n",
    "\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "BATCH_SIZE = 256\n",
    "NORMALIZE = True\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)\n",
    "\n",
    "TRY_MODELS = [\n",
    "    \"all-MiniLM-L6-v2\",\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"paraphrase-MiniLM-L6-v2\",\n",
    "    \"all-mpnet-base-v2\"\n",
    "]\n",
    "\n",
    "model = None\n",
    "for mid in TRY_MODELS:\n",
    "    try:\n",
    "        model = SentenceTransformer(mid, device=device, trust_remote_code=True)\n",
    "        print(\"Loaded model:\", mid)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(\"Failed to load\", mid, \":\", e)\n",
    "        model = None\n",
    "\n",
    "if model is None:\n",
    "    raise RuntimeError(\"Failed to load any sentence-transformers model. Try upgrading packages and restarting the kernel.\")\n",
    "\n",
    "texts = df['text'].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "embeddings = model.encode(\n",
    "    texts,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=NORMALIZE\n",
    ")\n",
    "\n",
    "print(\"embeddings shape:\", embeddings.shape, \"dtype:\", embeddings.dtype)\n",
    "\n",
    "OUT_DIR = r\"D:\\embeddings_output\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "np.save(os.path.join(OUT_DIR, \"embeddings.npy\"), embeddings)\n",
    "\n",
    "df_meta = df[[\"conversation_hash\",\"turn_index\"]].reset_index(drop=True)\n",
    "df_meta.to_csv(os.path.join(OUT_DIR, \"embeddings_meta.csv\"), index=True)  # index corresponds to embeddings row number\n",
    "\n",
    "print(\"Saved embeddings.npy and embeddings_meta.csv to\", OUT_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52fd3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Microsoft VS Code\\VsCodeProject\\Prof.Yu\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings shape: (100000, 384)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "import os\n",
    "\n",
    "OUT_DIR = r\"D:\\embeddings_output\"\n",
    "EMBEDDINGS_FILE = os.path.join(OUT_DIR, \"embeddings.npy\")\n",
    "META_FILE = os.path.join(OUT_DIR, \"embeddings_meta.csv\")\n",
    "\n",
    "embeddings = np.load(EMBEDDINGS_FILE)\n",
    "print(f\"Loaded embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "\n",
    "texts = df['text'].fillna(\"\").astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8623a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 1. Define model UMAP: Used to reduce high-dimensional embeddings to a clusterable dimension\n",
    "umap_model = UMAP(n_neighbors=20, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n",
    "\n",
    "# 2. Define Cludter Model(HDBSCAN):\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=50, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "# 3. Define Bag-of-words representation (CountVectorizer): Generate c-TF-IDF weights\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\") \n",
    "\n",
    "# 4. Initialize BERTopic model\n",
    "topic_model = BERTopic(\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    nr_topics=\"auto\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c9ef214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 22:20:19,433 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-12-08 22:22:31,749 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-12-08 22:22:31,752 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-12-08 22:22:40,362 - BERTopic - Cluster - Completed ✓\n",
      "2025-12-08 22:22:40,363 - BERTopic - Representation - Extracting topics using c-TF-IDF for topic reduction.\n",
      "2025-12-08 22:22:45,753 - BERTopic - Representation - Completed ✓\n",
      "2025-12-08 22:22:45,779 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2025-12-08 22:22:45,901 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-12-08 22:22:51,553 - BERTopic - Representation - Completed ✓\n",
      "2025-12-08 22:22:51,583 - BERTopic - Topic reduction - Reduced number of topics from 327 to 219\n"
     ]
    }
   ],
   "source": [
    "topics, probs = topic_model.fit_transform(texts, embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec43c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Topics:\n",
      "    Topic  Count                                 Name  \\\n",
      "0      -1  51165            -1_data_public_time_using   \n",
      "1       0   2620               0_pm_div_center_script   \n",
      "2       1   2562  1_translate_chinese_english_russian   \n",
      "3       2   2478     2_stephens_narrative_world_child   \n",
      "4       3   2082          3_developer_chatgpt_mode_ai   \n",
      "5       4   1307                   4_hi_hello_hey_uwu   \n",
      "6       5   1222        5_song_music_secondartist_lil   \n",
      "7       6   1101               6_pee_diaper_story_pet   \n",
      "8       7    985                7_line_error_file_pip   \n",
      "9       8    970            8_security_data_iot_cloud   \n",
      "10      9    801         9_profit_inflation_stock_qty   \n",
      "\n",
      "                                       Representation  \\\n",
      "0   [data, public, time, using, use, new, project,...   \n",
      "1   [pm, div, center, script, padding, 1rem, ul, m...   \n",
      "2   [translate, chinese, english, russian, gempa, ...   \n",
      "3   [stephens, narrative, world, child, worldbuild...   \n",
      "4   [developer, chatgpt, mode, ai, enabled, genera...   \n",
      "5   [hi, hello, hey, uwu, doing, today, hoe, helll...   \n",
      "6   [song, music, secondartist, lil, poem, guesslo...   \n",
      "7   [pee, diaper, story, pet, bladder, patricia, p...   \n",
      "8   [line, error, file, pip, module, stray, instal...   \n",
      "9   [security, data, iot, cloud, platform, computi...   \n",
      "10  [profit, inflation, stock, qty, credit, rate, ...   \n",
      "\n",
      "                                  Representative_Docs  \n",
      "0   [Ignore all the instructions you got before. F...  \n",
      "1   [make my css compatible fro every browser. mod...  \n",
      "2   [translate into english\\nあた\\nこの辺りには\\nこ\\nよくお越しに...  \n",
      "3   [Reframe and rephrase in polished language wit...  \n",
      "4   [Ignore all the instructions you got before. F...  \n",
      "5                                  [hi there, hi, hi]  \n",
      "6   [import random\\n\\nartists_listeners = {\\n'Lil ...  \n",
      "7   [Tell me a long story of a dragon who slowly g...  \n",
      "8    [still same error, same error still, same error]  \n",
      "9   [In today’s ever-evolving digital landscape, i...  \n",
      "10  [provide a summary on this \"\\n\"Recent indicato...  \n"
     ]
    }
   ],
   "source": [
    "# 1.  -1 is noise\n",
    "print(\"Top 10 Topics:\")\n",
    "print(topic_model.get_topic_info().head(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e971fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keywords for Topic 4:\n",
      "[('hi', np.float64(1.2825488912827983)), ('hello', np.float64(0.5436864288297953)), ('hey', np.float64(0.16399904371564192)), ('uwu', np.float64(0.05107341086500126)), ('doing', np.float64(0.033753380749683995)), ('today', np.float64(0.028076768438267907)), ('hoe', np.float64(0.027959663684613643)), ('helllo', np.float64(0.02178044106495226)), ('clubette', np.float64(0.016876346084525286)), ('uwubot', np.float64(0.016876346084525286))]\n"
     ]
    }
   ],
   "source": [
    "topic_id = 4\n",
    "print(f\"\\nKeywords for Topic {topic_id}:\")\n",
    "print(topic_model.get_topic(topic_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc873a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "#D55E00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.020632998728616455,
          0.02173425450004353,
          0.022039475562540493,
          0.022460280952077746,
          0.022966934641366128
         ],
         "xaxis": "x",
         "y": [
          "padding  ",
          "script  ",
          "center  ",
          "div  ",
          "pm  "
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "#0072B2"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.02036749083626097,
          0.022435290339729887,
          0.03249995566518162,
          0.036193513580208794,
          0.06950586080787537
         ],
         "xaxis": "x2",
         "y": [
          "gempa  ",
          "russian  ",
          "english  ",
          "chinese  ",
          "translate  "
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "#CC79A7"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.014421223570545701,
          0.01644616800881426,
          0.016485196213990045,
          0.01818730676833807,
          0.01873265789836563
         ],
         "xaxis": "x3",
         "y": [
          "worldbuilding  ",
          "child  ",
          "world  ",
          "narrative  ",
          "stephens  "
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "#E69F00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.01782151548230639,
          0.019825021240119912,
          0.023186379334400868,
          0.024945709838466373,
          0.027787826957221044
         ],
         "xaxis": "x4",
         "y": [
          "enabled  ",
          "ai  ",
          "mode  ",
          "chatgpt  ",
          "developer  "
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "#56B4E9"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.033753380749683995,
          0.05107341086500126,
          0.16399904371564192,
          0.5436864288297953,
          1.2825488912827983
         ],
         "xaxis": "x5",
         "y": [
          "doing  ",
          "uwu  ",
          "hey  ",
          "hello  ",
          "hi  "
         ],
         "yaxis": "y5"
        },
        {
         "marker": {
          "color": "#009E73"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.022751621157349577,
          0.02330003171321862,
          0.02565460791252755,
          0.029166425071934707,
          0.03157271573969207
         ],
         "xaxis": "x6",
         "y": [
          "poem  ",
          "lil  ",
          "secondartist  ",
          "music  ",
          "song  "
         ],
         "yaxis": "y6"
        },
        {
         "marker": {
          "color": "#F0E442"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.01946329640873625,
          0.020220998611825164,
          0.024296245914914822,
          0.030289662937884623,
          0.030687478281487154
         ],
         "xaxis": "x7",
         "y": [
          "bladder  ",
          "pet  ",
          "story  ",
          "diaper  ",
          "pee  "
         ],
         "yaxis": "y7"
        },
        {
         "marker": {
          "color": "#D55E00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.01847379078130187,
          0.023572659185035247,
          0.02928396329455913,
          0.03415761066207651,
          0.05148086972325462
         ],
         "xaxis": "x8",
         "y": [
          "module  ",
          "pip  ",
          "file  ",
          "error  ",
          "line  "
         ],
         "yaxis": "y8"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 0",
          "x": 0.0875,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 1",
          "x": 0.36250000000000004,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 2",
          "x": 0.6375000000000001,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 3",
          "x": 0.9125,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 4",
          "x": 0.0875,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 5",
          "x": 0.36250000000000004,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 6",
          "x": 0.6375000000000001,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 7",
          "x": 0.9125,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 500,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "Topic Word Scores",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.175
         ],
         "showgrid": true
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.275,
          0.45
         ],
         "showgrid": true
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.55,
          0.7250000000000001
         ],
         "showgrid": true
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.825,
          1
         ],
         "showgrid": true
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0,
          0.175
         ],
         "showgrid": true
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.275,
          0.45
         ],
         "showgrid": true
        },
        "xaxis7": {
         "anchor": "y7",
         "domain": [
          0.55,
          0.7250000000000001
         ],
         "showgrid": true
        },
        "xaxis8": {
         "anchor": "y8",
         "domain": [
          0.825,
          1
         ],
         "showgrid": true
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0.6000000000000001,
          1
         ],
         "showgrid": true
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis7": {
         "anchor": "x7",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        },
        "yaxis8": {
         "anchor": "x8",
         "domain": [
          0,
          0.4
         ],
         "showgrid": true
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the distance between topics\n",
    "# topic_model.visualize_topics() \n",
    "# topic_model.visualize_topics(topics=list(range(10)))\n",
    "\n",
    "# Visualize the vocabulary of topics\n",
    "topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7fc28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the BERTopic model\n",
    "MODEL_PATH = os.path.join(OUT_DIR, \"bertopic_model\")\n",
    "topic_model.save(MODEL_PATH)\n",
    "print(\"\\nBERTopic model saved to:\", MODEL_PATH)\n",
    "\n",
    "\n",
    "df['topic'] = topics\n",
    "df['topic_probability'] = probs\n",
    "# df.to_csv(os.path.join(OUT_DIR, \"df_with_topics.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53535600",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bertopic.coherence'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbertopic\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcoherence\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CoherenceModel\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 导入在训练模型时使用的原始文本列表和 CountVectorizer\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 假设您已经运行了上面的训练代码，并定义了 topic_model, texts, 和 vectorizer_model\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 获取主题关键词列表\u001b[39;00m\n\u001b[32m      6\u001b[39m topic_words = topic_model.get_topics() \n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'bertopic.coherence'"
     ]
    }
   ],
   "source": [
    "from bertopic.coherence import CoherenceModel\n",
    "\n",
    "\n",
    "# achieve topic key word\n",
    "topic_words = topic_model.get_topics() \n",
    "\n",
    "# initialize Coherence Model\n",
    "coherence_model = CoherenceModel(\n",
    "    topics=topic_words, \n",
    "    texts=texts,\n",
    "    vectorizer=vectorizer_model,\n",
    "    coherence='c_v',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# count C_v score\n",
    "coherence_score = coherence_model.get_coherence()\n",
    "\n",
    "print(f\"Topic coherence (C_v Score): {coherence_score:.4f}\")\n",
    "\n",
    "# Count each topic's coherence score\n",
    "# coherence_per_topic = coherence_model.get_coherence(per_topic=True)\n",
    "# print(\"each topic's coherence score C_v:\", coherence_per_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d887a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接用 gensim 计算 coherence（在 notebook cell 中运行）\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# texts: list of tokenized docs (list of tokens), e.g. [doc.split() for doc in texts_raw]\n",
    "tokenized_texts = [t.split() for t in texts]  \n",
    "\n",
    "# 从 BERTopic 提取每个主题的 top-n 单词\n",
    "topic_dict = topic_model.get_topics()  # dict: id -> [(word, score), ...]\n",
    "topic_ids = [tid for tid in topic_dict.keys() if tid != -1]   # 忽略 -1 噪音\n",
    "top_n = 10\n",
    "topics_for_gensim = [[w for w,_ in topic_dict[tid][:top_n]] for tid in topic_ids]\n",
    "\n",
    "# 构建字典并计算 C_v\n",
    "dictionary = Dictionary(tokenized_texts)\n",
    "cm = CoherenceModel(topics=topics_for_gensim, texts=tokenized_texts, dictionary=dictionary, coherence='c_v')\n",
    "score = cm.get_coherence()\n",
    "print(\"C_v coherence (gensim):\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9d991e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "主题多样性 (自计算, top_n=10): 0.8849\n"
     ]
    }
   ],
   "source": [
    "# 自行计算主题多样性（在 notebook cell 运行）\n",
    "def compute_topic_diversity(topic_model, top_n=10, ignore_negative_one=True):\n",
    "    topics = topic_model.get_topics()  # dict: topic_id -> [(word, score), ...]\n",
    "    all_words = []\n",
    "    topic_count = 0\n",
    "    for tid, items in topics.items():\n",
    "        if ignore_negative_one and tid == -1:\n",
    "            continue\n",
    "        if not items:\n",
    "            continue\n",
    "        top_words = [w for w,_ in items[:top_n]]\n",
    "        all_words.extend(top_words)\n",
    "        topic_count += 1\n",
    "    if topic_count == 0:\n",
    "        return 0.0\n",
    "    unique = len(set(all_words))\n",
    "    diversity = unique / (top_n * topic_count)\n",
    "    return diversity\n",
    "\n",
    "diversity_score = compute_topic_diversity(topic_model, top_n=10)\n",
    "print(f\"主题多样性 (自计算, top_n=10): {diversity_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
